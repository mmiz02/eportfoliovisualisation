**Week 7: Unsupervised Learning and Dimensionality Reduction**

In Week 7, I learned about unsupervised learning techniques and their role in exploring and understanding data without predefined labels. A key focus was the importance of dimensionality reduction, particularly in simplifying complex datasets while retaining the most meaningful structure within the data.

During the seminar and lab activities, I worked through examples from An Introduction to Statistical Learning with Applications in R, including Principal Component Analysis (PCA) and clustering methods. Applying PCA to the USArrests dataset helped me understand how high-dimensional data can be transformed into a smaller number of principal components that capture most of the variance. Visualising the first two principal components made it easier to identify patterns and relationships that were not immediately visible in the original variables.

I also explored K-means clustering and hierarchical clustering as unsupervised techniques for grouping similar observations. Visualising clusters alongside PCA plots demonstrated how dimensionality reduction can support and improve cluster interpretation. These visualisations helped highlight similarities between states in the dataset and provided insight into how different clustering methods can produce different group structures.

Overall, this week strengthened my understanding of how unsupervised visualisation techniques, such as PCA and clustering, can be used to explore structure, reduce complexity, and generate insight from data. It also reinforced the importance of visualisation in making high-dimensional data more interpretable and supporting exploratory data analysis.
